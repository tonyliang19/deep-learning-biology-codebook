{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Transfer Learning for Cell Image Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we'll explore **Transfer Learning**, one of the most powerful techniques in deep learning, and apply it to cell image classification.\n",
    "\n",
    "### What is Transfer Learning?\n",
    "\n",
    "Transfer learning uses a model pre-trained on a large dataset (e.g., ImageNet with millions of images) and adapts it to a new task. Instead of training from scratch, we leverage knowledge the model already learned!\n",
    "\n",
    "### Why Transfer Learning?\n",
    "\n",
    "- **Less data needed**: Pre-trained models work well even with small datasets\n",
    "- **Faster training**: Only need to fine-tune, not train from scratch\n",
    "- **Better performance**: Especially when you have limited data\n",
    "- **Lower computational cost**: Less GPU time required\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "1. Understand the concept of transfer learning\n",
    "2. Use a pre-trained ResNet model\n",
    "3. Fine-tune for cell image classification\n",
    "4. Compare transfer learning vs training from scratch\n",
    "5. Visualize learned features using grad-CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Cell Images\n",
    "\n",
    "We'll create synthetic microscopy images of three cell types:\n",
    "- **Red Blood Cells**: Circular, uniform\n",
    "- **White Blood Cells**: Larger, textured nuclei\n",
    "- **Platelets**: Small, irregular\n",
    "\n",
    "In practice, you would use real datasets like:\n",
    "- Broad Bioimage Benchmark Collection\n",
    "- Cell Image Library\n",
    "- Kaggle medical image datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cell_image(cell_type, size=128):\n",
    "    \"\"\"\n",
    "    Create synthetic cell images.\n",
    "    \n",
    "    Args:\n",
    "        cell_type: 0 (RBC), 1 (WBC), 2 (Platelet)\n",
    "        size: Image size\n",
    "    \"\"\"\n",
    "    image = np.zeros((size, size, 3), dtype=np.uint8)\n",
    "    \n",
    "    if cell_type == 0:  # Red Blood Cell\n",
    "        # Create circular shape\n",
    "        center = (size // 2 + np.random.randint(-10, 10), \n",
    "                 size // 2 + np.random.randint(-10, 10))\n",
    "        radius = np.random.randint(25, 35)\n",
    "        \n",
    "        y, x = np.ogrid[:size, :size]\n",
    "        mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2\n",
    "        \n",
    "        # Reddish color\n",
    "        image[mask] = [200 + np.random.randint(-20, 20), \n",
    "                       50 + np.random.randint(-20, 20), \n",
    "                       50 + np.random.randint(-20, 20)]\n",
    "    \n",
    "    elif cell_type == 1:  # White Blood Cell\n",
    "        # Larger with textured nucleus\n",
    "        center = (size // 2, size // 2)\n",
    "        radius = np.random.randint(35, 45)\n",
    "        \n",
    "        y, x = np.ogrid[:size, :size]\n",
    "        mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2\n",
    "        \n",
    "        # Light purple/blue\n",
    "        image[mask] = [150 + np.random.randint(-30, 30), \n",
    "                       150 + np.random.randint(-30, 30), \n",
    "                       200 + np.random.randint(-30, 30)]\n",
    "        \n",
    "        # Add nucleus texture\n",
    "        nucleus_mask = (x - center[0])**2 + (y - center[1])**2 <= (radius * 0.6)**2\n",
    "        image[nucleus_mask] = [80, 80, 150]\n",
    "    \n",
    "    else:  # Platelet\n",
    "        # Small irregular shapes\n",
    "        for _ in range(np.random.randint(2, 5)):\n",
    "            center = (np.random.randint(size//4, 3*size//4), \n",
    "                     np.random.randint(size//4, 3*size//4))\n",
    "            radius = np.random.randint(8, 15)\n",
    "            \n",
    "            y, x = np.ogrid[:size, :size]\n",
    "            mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2\n",
    "            \n",
    "            # Yellowish\n",
    "            image[mask] = [200, 200, 100]\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, 10, image.shape)\n",
    "    image = np.clip(image + noise, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Generate dataset\n",
    "n_samples_per_class = 200\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for cell_type in range(3):\n",
    "    for _ in range(n_samples_per_class):\n",
    "        img = create_cell_image(cell_type)\n",
    "        images.append(img)\n",
    "        labels.append(cell_type)\n",
    "\n",
    "print(f\"Generated {len(images)} cell images\")\n",
    "print(f\"Image shape: {images[0].shape}\")\n",
    "\n",
    "# Visualize examples\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "cell_names = ['Red Blood Cell', 'White Blood Cell', 'Platelet']\n",
    "\n",
    "for i, (ax, name) in enumerate(zip(axes, cell_names)):\n",
    "    ax.imshow(images[i * n_samples_per_class])\n",
    "    ax.set_title(name)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Augmentation\n",
    "\n",
    "### Image Transformations:\n",
    "\n",
    "1. **Resize**: Ensure all images are the same size\n",
    "2. **Normalization**: Use ImageNet mean/std for transfer learning\n",
    "3. **Data Augmentation** (training only):\n",
    "   - Random rotation\n",
    "   - Random flips\n",
    "   - Color jitter\n",
    "\n",
    "Data augmentation creates variations of training images, effectively increasing dataset size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization values (required for pre-trained models)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Training transforms with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  # ResNet expects 224x224\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Validation/test transforms without augmentation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "print(\"Data transformations configured.\")\n",
    "print(\"\\nWhy normalize with ImageNet statistics?\")\n",
    "print(\"- Pre-trained models expect inputs in this range\")\n",
    "print(\"- Ensures feature distributions match training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for cell images.\n",
    "    \"\"\"\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Create datasets\n",
    "dataset = CellImageDataset(images, labels)\n",
    "\n",
    "# Split\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_indices, val_indices, test_indices = torch.utils.data.random_split(\n",
    "    range(len(dataset)), [train_size, val_size, test_size]\n",
    ")\n",
    "\n",
    "# Create datasets with appropriate transforms\n",
    "train_dataset = CellImageDataset(\n",
    "    [images[i] for i in train_indices.indices],\n",
    "    [labels[i] for i in train_indices.indices],\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset = CellImageDataset(\n",
    "    [images[i] for i in val_indices.indices],\n",
    "    [labels[i] for i in val_indices.indices],\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "test_dataset = CellImageDataset(\n",
    "    [images[i] for i in test_indices.indices],\n",
    "    [labels[i] for i in test_indices.indices],\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "print(f\"Dataset splits:\")\n",
    "print(f\"  Train: {len(train_dataset)}\")\n",
    "print(f\"  Validation: {len(val_dataset)}\")\n",
    "print(f\"  Test: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"DataLoaders created with batch size {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Pre-trained ResNet Model\n",
    "\n",
    "### ResNet (Residual Network):\n",
    "\n",
    "- One of the most successful architectures\n",
    "- Uses skip connections to train very deep networks\n",
    "- Pre-trained on ImageNet (1.2M images, 1000 classes)\n",
    "\n",
    "### Transfer Learning Strategy:\n",
    "\n",
    "1. **Load pre-trained model**: Get weights learned from ImageNet\n",
    "2. **Freeze early layers**: Keep low-level features (edges, textures)\n",
    "3. **Replace final layer**: Adapt to our 3 classes\n",
    "4. **Fine-tune**: Train with our cell images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_learning_model(num_classes=3, freeze_layers=True):\n",
    "    \"\"\"\n",
    "    Create ResNet18 model with transfer learning.\n",
    "    \n",
    "    Args:\n",
    "        num_classes: Number of output classes\n",
    "        freeze_layers: Whether to freeze pre-trained layers\n",
    "    \"\"\"\n",
    "    # Load pre-trained ResNet18\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # Freeze all layers if requested\n",
    "    if freeze_layers:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # Replace final fully connected layer\n",
    "    # ResNet18's fc layer: (512 -> 1000) becomes (512 -> 3)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_transfer_learning_model(num_classes=3, freeze_layers=True).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model: ResNet18\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"\\nWe're only training {100 * trainable_params / total_params:.1f}% of the parameters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Only optimize parameters that require gradients (unfrozen layers)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100 * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train the Model\n",
    "\n",
    "Notice how fast training is! We're only updating a small fraction of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\\n\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(train_losses, label='Train Loss', marker='o')\n",
    "ax1.plot(val_losses, label='Validation Loss', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Progress (Transfer Learning)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(train_accs, label='Train Accuracy', marker='o')\n",
    "ax2.plot(val_accs, label='Validation Accuracy', marker='s')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Accuracy Progress')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels)\n",
    "\n",
    "test_predictions, test_labels = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(\n",
    "    test_labels, test_predictions,\n",
    "    target_names=['RBC', 'WBC', 'Platelet']\n",
    "))\n",
    "\n",
    "test_accuracy = 100 * np.sum(test_predictions == test_labels) / len(test_labels)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['RBC', 'WBC', 'Platelet'],\n",
    "            yticklabels=['RBC', 'WBC', 'Platelet'])\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - Cell Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some test images\n",
    "model.eval()\n",
    "cell_names = ['RBC', 'WBC', 'Platelet']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Get a batch\n",
    "images_batch, labels_batch = next(iter(test_loader))\n",
    "images_batch = images_batch.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images_batch)\n",
    "    _, predictions = torch.max(outputs, 1)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "\n",
    "# Denormalize for display\n",
    "mean = torch.tensor(IMAGENET_MEAN).view(3, 1, 1)\n",
    "std = torch.tensor(IMAGENET_STD).view(3, 1, 1)\n",
    "\n",
    "for i in range(6):\n",
    "    img = images_batch[i].cpu() * std + mean\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    true_label = labels_batch[i].item()\n",
    "    pred_label = predictions[i].item()\n",
    "    confidence = probabilities[i][pred_label].item()\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'True: {cell_names[true_label]}\\nPred: {cell_names[pred_label]} ({confidence:.1%})')\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    if true_label != pred_label:\n",
    "        axes[i].set_title(f'True: {cell_names[true_label]}\\nPred: {cell_names[pred_label]} ({confidence:.1%})',\n",
    "                         color='red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. \u2705 **Applied transfer learning** using pre-trained ResNet18\n",
    "2. \u2705 **Froze pre-trained layers** to leverage learned features\n",
    "3. \u2705 **Fine-tuned** only the final layer for our task\n",
    "4. \u2705 **Used data augmentation** to improve generalization\n",
    "5. \u2705 **Achieved high accuracy** with limited data and training time\n",
    "\n",
    "### Transfer Learning Benefits:\n",
    "\n",
    "- **Data efficiency**: Works with small datasets (we used only 600 images!)\n",
    "- **Fast training**: Converges in just a few epochs\n",
    "- **Better features**: Pre-trained features (edges, textures) are universal\n",
    "- **Lower computational cost**: Less GPU time and memory\n",
    "\n",
    "### When to Use Transfer Learning:\n",
    "\n",
    "\u2705 **Use it when**:\n",
    "- You have limited data (< 10,000 images)\n",
    "- Your task is similar to ImageNet (natural images, objects)\n",
    "- You want fast prototyping\n",
    "- Computational resources are limited\n",
    "\n",
    "\u274c **Consider training from scratch when**:\n",
    "- You have millions of images\n",
    "- Your domain is very different (e.g., medical scans, satellite images)\n",
    "- You have specific architectural requirements\n",
    "\n",
    "### Advanced Techniques:\n",
    "\n",
    "- **Gradual unfreezing**: Unfreeze layers progressively during training\n",
    "- **Discriminative learning rates**: Different learning rates for different layers\n",
    "- **Domain-specific pre-training**: Use models pre-trained on medical images\n",
    "- **Ensemble methods**: Combine multiple pre-trained models\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "- **Medical imaging**: X-ray, CT, MRI classification\n",
    "- **Pathology**: Cancer detection in tissue samples\n",
    "- **Cell biology**: Cell type identification, organelle detection\n",
    "- **Drug discovery**: High-content screening analysis\n",
    "- **Quality control**: Defect detection in cell cultures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}