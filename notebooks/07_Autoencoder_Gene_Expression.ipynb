{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Autoencoder for Gene Expression Analysis\n",
    "\n",
    "Welcome to unsupervised learning with autoencoders! \ud83e\uddec\n",
    "\n",
    "In this notebook, we'll explore a different type of deep learning: **unsupervised learning**. We'll use autoencoders to analyze gene expression data and discover hidden patterns.\n",
    "\n",
    "## \ud83c\udfaf The Biological Problem\n",
    "\n",
    "### What is Gene Expression Data?\n",
    "\n",
    "Gene expression tells us how active each gene is in a cell:\n",
    "\n",
    "- **Measurement:** RNA sequencing (RNA-seq) or microarrays\n",
    "- **Data format:** For each sample (patient, cell, tissue), measure expression of ~20,000 genes\n",
    "- **Result:** A matrix where each row is a sample, each column is a gene\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Sample    Gene1  Gene2  Gene3  ... Gene20000\n",
    "Patient1   5.2    0.1    8.9   ...    2.3\n",
    "Patient2   5.5    0.2    8.7   ...    2.1\n",
    "```\n",
    "\n",
    "### The Challenge: Too Many Dimensions!\n",
    "\n",
    "- **20,000 dimensions** (one per gene) is impossible to visualize or analyze directly\n",
    "- Many genes are correlated (they work together)\n",
    "- We want to find the **underlying patterns** that explain the data\n",
    "\n",
    "### Traditional Approach: PCA\n",
    "\n",
    "Principal Component Analysis (PCA) is the classical method:\n",
    "- Linear dimensionality reduction\n",
    "- Fast and interpretable\n",
    "- But: Only finds linear relationships\n",
    "\n",
    "### Deep Learning Approach: Autoencoders\n",
    "\n",
    "Autoencoders are neural networks that:\n",
    "- Learn to compress data (many dimensions \u2192 few dimensions)\n",
    "- Then reconstruct the original data\n",
    "- Can capture **non-linear** relationships\n",
    "\n",
    "**Analogy:** Like learning to describe a movie (2 hour video) in a few sentences (compression), then using those sentences to recreate the plot (reconstruction).\n",
    "\n",
    "## \ud83d\udcda What You'll Learn\n",
    "\n",
    "1. **Autoencoder Architecture:** Encoder \u2192 Bottleneck \u2192 Decoder\n",
    "2. **Latent Space:** The compressed representation in the middle\n",
    "3. **Dimensionality Reduction:** From 20,000 genes to 2-10 dimensions\n",
    "4. **Clustering:** Finding groups of similar samples\n",
    "5. **Comparison with PCA:** When to use each method\n",
    "\n",
    "## \ud83d\udd27 Applications in Biology\n",
    "\n",
    "- **Disease subtyping:** Find different types of cancer based on gene expression\n",
    "- **Biomarker discovery:** Identify genes that distinguish healthy vs diseased\n",
    "- **Cell type identification:** Classify cells in single-cell RNA-seq data\n",
    "- **Data visualization:** Plot high-dimensional data in 2D\n",
    "\n",
    "Let's compress some genes! \ud83d\ude80\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Gene Expression Data\n",
    "\n",
    "We'll simulate gene expression data for three different conditions:\n",
    "- **Condition A**: Healthy samples\n",
    "- **Condition B**: Disease state 1\n",
    "- **Condition C**: Disease state 2\n",
    "\n",
    "Each condition will have characteristic gene expression patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gene_expression_data(n_samples=300, n_genes=2000, n_informative=200):\n",
    "    \"\"\"\n",
    "    Generate synthetic gene expression data.\n",
    "    \n",
    "    Args:\n",
    "        n_samples: Number of samples per condition\n",
    "        n_genes: Total number of genes\n",
    "        n_informative: Number of genes that differ between conditions\n",
    "    \n",
    "    Returns:\n",
    "        data: Gene expression matrix (samples x genes)\n",
    "        labels: Sample labels (0, 1, 2 for three conditions)\n",
    "        gene_names: List of gene names\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate gene names\n",
    "    gene_names = [f\"Gene_{i:04d}\" for i in range(n_genes)]\n",
    "    \n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for condition in range(3):\n",
    "        # Base expression: log-normal distribution (typical for RNA-seq)\n",
    "        base_expression = np.random.lognormal(mean=5, sigma=1.5, size=(n_samples, n_genes))\n",
    "        \n",
    "        # Add condition-specific patterns to informative genes\n",
    "        informative_indices = np.random.choice(n_genes, n_informative, replace=False)\n",
    "        \n",
    "        if condition == 0:  # Healthy\n",
    "            # Slightly elevated expression in some genes\n",
    "            base_expression[:, informative_indices[:100]] *= np.random.uniform(1.5, 2.5, 100)\n",
    "        \n",
    "        elif condition == 1:  # Disease 1\n",
    "            # Upregulated inflammatory genes\n",
    "            base_expression[:, informative_indices[:50]] *= np.random.uniform(3, 5, 50)\n",
    "            # Downregulated housekeeping genes\n",
    "            base_expression[:, informative_indices[50:100]] *= np.random.uniform(0.2, 0.5, 50)\n",
    "        \n",
    "        else:  # Disease 2\n",
    "            # Different pattern - metabolic changes\n",
    "            base_expression[:, informative_indices[100:150]] *= np.random.uniform(4, 6, 50)\n",
    "            base_expression[:, informative_indices[150:200]] *= np.random.uniform(0.1, 0.3, 50)\n",
    "        \n",
    "        # Add technical noise\n",
    "        noise = np.random.normal(0, 0.1, base_expression.shape)\n",
    "        expression_data = base_expression + noise\n",
    "        expression_data = np.maximum(expression_data, 0)  # No negative expression\n",
    "        \n",
    "        all_data.append(expression_data)\n",
    "        all_labels.extend([condition] * n_samples)\n",
    "    \n",
    "    data = np.vstack(all_data)\n",
    "    labels = np.array(all_labels)\n",
    "    \n",
    "    # Log-transform (common preprocessing for gene expression)\n",
    "    data = np.log1p(data)\n",
    "    \n",
    "    return data, labels, gene_names\n",
    "\n",
    "# Generate data\n",
    "data, labels, gene_names = generate_gene_expression_data(\n",
    "    n_samples=200, n_genes=2000, n_informative=200\n",
    ")\n",
    "\n",
    "print(f\"Generated gene expression data:\")\n",
    "print(f\"  Shape: {data.shape} (samples x genes)\")\n",
    "print(f\"  Conditions: 0 (n={np.sum(labels==0)}), 1 (n={np.sum(labels==1)}), 2 (n={np.sum(labels==2)})\")\n",
    "print(f\"  Expression range: [{data.min():.2f}, {data.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Visualization\n",
    "\n",
    "Before building the autoencoder, let's:\n",
    "1. Standardize the data (zero mean, unit variance)\n",
    "2. Visualize the data distribution\n",
    "3. Check correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Visualize expression distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Distribution before scaling\n",
    "axes[0].hist(data.flatten(), bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_xlabel('Log Expression')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Expression Distribution (Original)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution after scaling\n",
    "axes[1].hist(data_scaled.flatten(), bins=50, alpha=0.7, edgecolor='black', color='orange')\n",
    "axes[1].set_xlabel('Scaled Expression')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Expression Distribution (Scaled)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Sample-wise mean expression\n",
    "for condition in range(3):\n",
    "    condition_data = data[labels == condition].mean(axis=1)\n",
    "    axes[2].hist(condition_data, bins=20, alpha=0.5, \n",
    "                label=f'Condition {condition}', edgecolor='black')\n",
    "axes[2].set_xlabel('Mean Expression per Sample')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Expression by Condition')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create PyTorch Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.FloatTensor(data_scaled)\n",
    "y_tensor = torch.LongTensor(labels)\n",
    "\n",
    "# Create dataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split into train and test (80/20)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Dataset splits:\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Test: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the Autoencoder\n",
    "\n",
    "### Autoencoder Architecture:\n",
    "\n",
    "An autoencoder has two parts:\n",
    "\n",
    "1. **Encoder**: Compresses input to a lower-dimensional representation (bottleneck/latent space)\n",
    "   - Input: 2000 genes\n",
    "   - Hidden layers: 1024 \u2192 512 \u2192 256\n",
    "   - Latent space: 32 dimensions\n",
    "\n",
    "2. **Decoder**: Reconstructs the original input from the latent representation\n",
    "   - Latent: 32 dimensions\n",
    "   - Hidden layers: 256 \u2192 512 \u2192 1024\n",
    "   - Output: 2000 genes\n",
    "\n",
    "The model learns by trying to reconstruct its input, forcing it to learn meaningful patterns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneExpressionAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder for gene expression dimensionality reduction.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=2000, latent_dim=32):\n",
    "        super(GeneExpressionAutoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder: Compresses data to latent representation\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),  # Normalizes activations\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, latent_dim)  # Bottleneck layer\n",
    "        )\n",
    "        \n",
    "        # Decoder: Reconstructs data from latent representation\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(1024, input_dim)  # Reconstruct original dimensions\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        latent = self.encoder(x)\n",
    "        # Decode\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Get latent representation only.\"\"\"\n",
    "        return self.encoder(x)\n",
    "\n",
    "# Create model\n",
    "input_dim = data_scaled.shape[1]\n",
    "latent_dim = 32\n",
    "model = GeneExpressionAutoencoder(input_dim=input_dim, latent_dim=latent_dim).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\nCompression ratio: {input_dim}/{latent_dim} = {input_dim/latent_dim:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Setup\n",
    "\n",
    "### Loss Function: Mean Squared Error (MSE)\n",
    "Measures how well the reconstruction matches the original input. Lower MSE means better reconstruction.\n",
    "\n",
    "### Why MSE for Autoencoders?\n",
    "We want to minimize the difference between input and reconstructed output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: MSE for reconstruction\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop\n",
    "\n",
    "The autoencoder learns to reconstruct its input. The better it compresses and reconstructs, the better it has learned the underlying structure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train autoencoder for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_data, _ in tqdm(loader, desc=\"Training\"):\n",
    "        batch_data = batch_data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: try to reconstruct input\n",
    "        reconstructed = model(batch_data)\n",
    "        \n",
    "        # Calculate reconstruction loss\n",
    "        loss = criterion(reconstructed, batch_data)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate autoencoder.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, _ in loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            reconstructed = model(batch_data)\n",
    "            loss = criterion(reconstructed, batch_data)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Training\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss = validate(model, test_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.6f}\")\n",
    "        print(f\"  Test Loss: {test_loss:.6f}\\n\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Train Loss', marker='o', markersize=3)\n",
    "plt.plot(test_losses, label='Test Loss', marker='s', markersize=3)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Reconstruction Loss (MSE)')\n",
    "plt.title('Autoencoder Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final training loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"Final test loss: {test_losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Extract Latent Representations\n",
    "\n",
    "Now let's use the trained encoder to get 32-dimensional representations of all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latent_representations(model, data_tensor, device):\n",
    "    \"\"\"\n",
    "    Extract latent representations from trained autoencoder.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data_tensor = data_tensor.to(device)\n",
    "        latent = model.encode(data_tensor)\n",
    "    return latent.cpu().numpy()\n",
    "\n",
    "# Get latent representations for all data\n",
    "latent_representations = get_latent_representations(model, X_tensor, device)\n",
    "\n",
    "print(f\"Latent representations shape: {latent_representations.shape}\")\n",
    "print(f\"Original data shape: {data_scaled.shape}\")\n",
    "print(f\"Dimensionality reduction: {data_scaled.shape[1]} \u2192 {latent_representations.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize Latent Space with t-SNE\n",
    "\n",
    "We'll use t-SNE to visualize the 32-dimensional latent space in 2D. If the autoencoder learned well, samples from the same condition should cluster together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE for visualization\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "latent_tsne = tsne.fit_transform(latent_representations)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Autoencoder latent space\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "condition_names = ['Healthy', 'Disease 1', 'Disease 2']\n",
    "\n",
    "for i, (color, name) in enumerate(zip(colors, condition_names)):\n",
    "    mask = labels == i\n",
    "    axes[0].scatter(latent_tsne[mask, 0], latent_tsne[mask, 1], \n",
    "                   c=color, label=name, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "axes[0].set_xlabel('t-SNE Dimension 1')\n",
    "axes[0].set_ylabel('t-SNE Dimension 2')\n",
    "axes[0].set_title('Autoencoder Latent Space (32D \u2192 2D via t-SNE)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Compare with PCA on original data\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(data_scaled)\n",
    "\n",
    "for i, (color, name) in enumerate(zip(colors, condition_names)):\n",
    "    mask = labels == i\n",
    "    axes[1].scatter(pca_result[mask, 0], pca_result[mask, 1], \n",
    "                   c=color, label=name, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "axes[1].set_title('PCA on Original Data (2000D \u2192 2D)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Autoencoder learns non-linear relationships\")\n",
    "print(\"- PCA only captures linear relationships\")\n",
    "print(\"- Both show separation of conditions, but autoencoder may capture more complex patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Clustering in Latent Space\n",
    "\n",
    "Let's use K-means clustering on the latent representations to see if we can recover the three conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(latent_representations)\n",
    "\n",
    "# Calculate clustering accuracy (best match between clusters and true labels)\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def clustering_accuracy(true_labels, cluster_labels):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy by finding best label assignment.\n",
    "    \"\"\"\n",
    "    # Create confusion matrix\n",
    "    n_clusters = len(np.unique(cluster_labels))\n",
    "    n_classes = len(np.unique(true_labels))\n",
    "    confusion = np.zeros((n_classes, n_clusters), dtype=int)\n",
    "    \n",
    "    for i in range(len(true_labels)):\n",
    "        confusion[true_labels[i], cluster_labels[i]] += 1\n",
    "    \n",
    "    # Find best assignment using Hungarian algorithm\n",
    "    row_ind, col_ind = linear_sum_assignment(-confusion)\n",
    "    \n",
    "    accuracy = confusion[row_ind, col_ind].sum() / len(true_labels)\n",
    "    return accuracy, dict(zip(col_ind, row_ind))\n",
    "\n",
    "accuracy, mapping = clustering_accuracy(labels, cluster_labels)\n",
    "\n",
    "print(f\"Clustering accuracy: {accuracy:.2%}\")\n",
    "print(f\"\\nCluster to condition mapping: {mapping}\")\n",
    "\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(3):\n",
    "    mask = cluster_labels == i\n",
    "    plt.scatter(latent_tsne[mask, 0], latent_tsne[mask, 1], \n",
    "               label=f'Cluster {i}', alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.title(f'K-means Clustering in Latent Space (Accuracy: {accuracy:.1%})')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualize Reconstruction Quality\n",
    "\n",
    "Let's check how well the autoencoder reconstructs the original gene expression profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reconstructions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_tensor_gpu = X_tensor.to(device)\n",
    "    reconstructed = model(X_tensor_gpu).cpu().numpy()\n",
    "\n",
    "# Plot original vs reconstructed for a few samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "sample_indices = np.random.choice(len(data_scaled), 6, replace=False)\n",
    "\n",
    "for idx, sample_idx in enumerate(sample_indices):\n",
    "    original = data_scaled[sample_idx]\n",
    "    recon = reconstructed[sample_idx]\n",
    "    condition = labels[sample_idx]\n",
    "    \n",
    "    # Plot first 100 genes\n",
    "    axes[idx].plot(original[:100], label='Original', alpha=0.7, linewidth=1)\n",
    "    axes[idx].plot(recon[:100], label='Reconstructed', alpha=0.7, linewidth=1)\n",
    "    axes[idx].set_xlabel('Gene Index')\n",
    "    axes[idx].set_ylabel('Scaled Expression')\n",
    "    axes[idx].set_title(f'Sample {sample_idx} (Condition {condition})')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate reconstruction error\n",
    "mse = np.mean((data_scaled - reconstructed) ** 2)\n",
    "print(f\"\\nMean reconstruction error (MSE): {mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Identify Important Features in Latent Space\n",
    "\n",
    "We can analyze the decoder weights to understand which genes are most important for each latent dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get decoder weights (last layer)\n",
    "decoder_weights = model.decoder[-1].weight.data.cpu().numpy()  # Shape: (n_genes, latent_dim)\n",
    "\n",
    "# For each latent dimension, find top genes\n",
    "n_top_genes = 10\n",
    "print(\"Top genes associated with each latent dimension:\\n\")\n",
    "\n",
    "for dim in range(min(5, latent_dim)):  # Show first 5 dimensions\n",
    "    weights = decoder_weights[:, dim]\n",
    "    top_indices = np.argsort(np.abs(weights))[-n_top_genes:]\n",
    "    \n",
    "    print(f\"Latent Dimension {dim}:\")\n",
    "    for idx in reversed(top_indices):\n",
    "        print(f\"  {gene_names[idx]}: {weights[idx]:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Visualize latent dimension importance\n",
    "latent_variance = np.var(latent_representations, axis=0)\n",
    "sorted_indices = np.argsort(latent_variance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(range(latent_dim), latent_variance[sorted_indices])\n",
    "plt.xlabel('Latent Dimension (sorted by variance)')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Variance Explained by Each Latent Dimension')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop 10 latent dimensions explain {100 * latent_variance[sorted_indices[:10]].sum() / latent_variance.sum():.1f}% of variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. \u2705 **Built an autoencoder** for unsupervised dimensionality reduction\n",
    "2. \u2705 **Compressed** 2000-dimensional gene expression to 32 dimensions\n",
    "3. \u2705 **Visualized** the learned latent space using t-SNE\n",
    "4. \u2705 **Compared** with traditional PCA\n",
    "5. \u2705 **Performed clustering** in the latent space\n",
    "6. \u2705 **Analyzed** reconstruction quality\n",
    "\n",
    "### Why Autoencoders for Gene Expression?\n",
    "\n",
    "- **Non-linear dimensionality reduction**: Captures complex patterns PCA misses\n",
    "- **Unsupervised learning**: No labels needed\n",
    "- **Denoising**: Can be trained to remove technical noise\n",
    "- **Feature learning**: Discovers biologically meaningful representations\n",
    "- **Scalability**: Handles high-dimensional data efficiently\n",
    "\n",
    "### Advanced Techniques:\n",
    "\n",
    "- **Variational Autoencoders (VAE)**: Add probabilistic structure\n",
    "- **Denoising Autoencoders**: Train with corrupted input\n",
    "- **Sparse Autoencoders**: Encourage sparse activations\n",
    "- **Adversarial Autoencoders**: Use GANs for better latent space\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "- **Cancer subtype discovery**: Find new cancer subtypes from expression\n",
    "- **Drug response prediction**: Predict treatment outcomes\n",
    "- **Single-cell RNA-seq**: Analyze individual cell transcriptomes\n",
    "- **Batch effect correction**: Remove technical variation\n",
    "- **Data imputation**: Fill in missing values\n",
    "- **Biomarker discovery**: Identify diagnostic markers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}